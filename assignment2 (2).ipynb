{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c2728a-76b8-42be-a757-3887a0693739",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 1\n",
    "    \n",
    "Clusters are visually represented in a hierarchical tree called a dendrogram. Hierarchical clustering has a couple\n",
    "of key benefits: There is no need to pre-specify the number of clusters.\n",
    "Instead, the dendrogram can be cut at the appropriate level to obtain the desired number of clusters.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e9b9ae-131f-4765-8e85-7b0417c1380b",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 2\n",
    "    \n",
    "Agglomerative: This is a \"bottom-up\" approach: Each observation starts in its own cluster, and pairs of clusters are\n",
    "merged as one moves up the hierarchy. Divisive: This is a \"top-down\" approach: \n",
    "All observations start in one cluster, and splits are performed recursively as one moves down the hierarchy.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25890455-ef4b-4fda-b5c2-01c610bc0781",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 3\n",
    "  \n",
    "For most common hierarchical clustering software, the default distance measure is the Euclidean distance. \n",
    "This is the square root of the sum of the square differences. However, for gene expression, correlation distance \n",
    "is often used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bca7a82-ce04-4370-9bc4-01c80ba57d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 4\n",
    "    \n",
    "Elbow Method\n",
    "It is the most popular method for determining the optimal number of clusters. The method is based on calculating\n",
    "the Within-Cluster-Sum of Squared Errors (WSS) for different number of clusters (k) and selecting the k for which \n",
    "change in WSS first starts to diminish.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10184125-1a6e-4256-a5b1-50cbe9b33a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 5\n",
    "   \n",
    "A dendrogram is a diagram that shows the hierarchical relationship between objects. \n",
    "It is most commonly created as an output from hierarchical clustering. \n",
    "The main use of a dendrogram is to work out the best way to allocate objects to clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce87d961-3590-48a8-b27d-704d6e04f66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 6\n",
    "   \n",
    "Yes, hierarchical clustering can be used for both numerical and categorical data. However, the choice of distance metric or similarity measure differs between the two types of data.\n",
    "\n",
    "For numerical data:\n",
    "- Euclidean distance is the most commonly used distance metric for numerical data in hierarchical clustering. It measures the straight-line distance between two data points in the multidimensional space.\n",
    "- Other distance metrics such as Manhattan distance (city block distance), Chebyshev distance (maximum absolute difference), or Mahalanobis distance (accounts for correlations between variables) can also be used based on the specific characteristics of the data.\n",
    "\n",
    "For categorical data:\n",
    "- Categorical data requires a different approach since there is no natural notion of distance between categories. Instead, similarity measures such as Jaccard coefficient, Dice coefficient, or Hamming distance are commonly used.\n",
    "- Jaccard coefficient measures the similarity between two sets by comparing the intersection over the union of the sets.\n",
    "- Dice coefficient is similar to Jaccard coefficient but emphasizes shared elements over non-shared elements.\n",
    "- Hamming distance measures the number of positions at which the corresponding symbols are different in two strings of equal length.\n",
    "\n",
    "In some cases, it's also possible to transform categorical data into numerical data using techniques like one-hot encoding or encoding categorical variables into ordinal values. Once transformed, numerical distance metrics can be applied. However, this approach may not always capture the underlying relationships in the categorical data accurately. Therefore, it's essential to choose distance metrics or similarity measures that are appropriate for the data type to ensure meaningful clustering results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8135e5ba-9442-4b15-918f-d3665e14e122",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Answer: 7\n",
    "   \n",
    "One way to use clustering to detect outliers is to measure the distance or similarity between each data point and \n",
    "its assigned cluster. Data points that are far away from their cluster center, or have a low similarity score, can \n",
    "be considered as potential outliers, as they do not fit well into any cluster."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
